---
title: "Megabummer"
output: html_document
---

### Data Science BIO 260 Final Project, Spring 2016
##### Allison Blajda, Leo Brown, and Emily Lisker

### Overview and Motivation

Social media users leave digital traces that can be leveraged to guide consumer purchasing decisions. Twitter users, in particular, provide temporal data that can be analyzed to develop a more precise understanding of usersâ€™ perspectives or sentiments about a service, company, or product. This information, in turn, can be shared with the public to allow customers to make decisions based on crowd-sourced knowledge. It may also even help the service provider understand how they can improve their services.

Imagine it is Friday in July and you are finishing up a long week at the office. The clock reads 4:00pm and you quickly race to pack up your work station. You need to get downtown to catch the 5pm MegaBus from NYC to Washington, DC. You are ready to start the weekend and have plans at 10pm in downtown DC. You naviate the NYC subway and break a sweat walking quickly down 34th Street, hoping that you are early enough to score an aisle seat. As you approach the bus stop you come into view of your worst nightmare: a line with hundreds of angry Megabus passengers waiting with no bus in sight. As you walk towards the end of the line another passenger mentions that the 3:30pm bus hasn't arrived yet. A Megabus employee tells you he has no idea when the 5pm bus will depart ("Who knows..."). It is 90 degrees, you are sweating profusely, and you will surely miss your evening plans. You feel helpless. A wronged consumer with no recourse. Then you remember a social media site called Twitter...

Based on our personal experience and the experience of others, we aim to analyze recent tweets to understand the degree of positive and negative sentiment among users of the low-cost bus company, Megabus, over time. While Megabus is an inexpensive and convenient transportation option with many buses departing major cities each day, we hypothesized that some days or times of year may be more reliable, i.e., buses have fewer breakdowns and delays, than others. Using social media, data visualization and statistics we provide an informative and entertaining sentiment analysis of Megabus experiences from January 1, 2016 to April 1, 2016. Our work offers future bus riders information on the type of experience they can expect when riding the Megabus.

### Related Work: 

Sentiment analysis performed by our very own TA, David Robinson provided initial guiding inspiration for this this work (https://github.com/juliasilge/tidytext).

We were also inspired by sentiment analysis of Twitter data related to current events. Some examples of other analyses that we explored includes: http://www.wired.com/2015/02/best-worst-public-transit-systems-according-twitter/#slide-2 and https://medium.com/mit-media-lab/introducing-tonar-3bf161cba369#.gixrkibqj

### Initial Questions: 

As a team, we were originally interested in building a predictive model for Megabus experience based on time of day, location and bus route. Based on the data that we were able to collect from Twitter, these questions evolved to focus on the relationship between Megabus passenger sentiment, the volume of Megabus tweets, day of the week, whether the tweet was posted on a weekday (Monday-Thursday) or a weekend (Friday-Sunday), and month of the year.  

The questions we have answered as part of this analysis include the following:
1. How can we most effectively scrape Twitter for data related to Megabus sentiment?
2. What is overall Megabus sentiment and volume of Megabus tweets during the period from January 1, 2015 to April 1, 2016?
3. How does Megabus sentiment and volume of tweets differ based on day of the week and month of the year?
4. What is the realtionship between volume of Megabus tweets on a given day and the overall sentiment we expect to see?

### Data: 

#### Data Scraping and Tidying
We scraped tweets with the keyword "megabus" during the period of January 1, 2015 through December 31, 2015 from the Twitter API using python package... 
[LEO TO UPDATE with what he actually did - did you have to use tidytext?] 

We imported four csv files, one for each quarter of tweets, as dataframes and thencombined the four quarters into one dataframe for the entire year. In order to look at variations in sentiment over days and time, we parsed the combined date and time variable into two new variables, containing just date and time information. 

We cleaned the data using dplyr and the tidytext package, in order to help with the text mining tasks necessary for sentiment analysis, available here: https://github.com/juliasilge/tidytext. 

#### Sentiment Analysis
Like most sentiment analyses, we relied on a lexicon of positive and negative words. We started with the Bing lexicon in the tidytext package in the sentiment dataset (described here in more detail https://www.cs.uic.edu/~liub/). This lexicon has been compiled over the past 12 years by researchers at the University of Illinois at Chicago. 

After initial review of the Bing lexicon, we realized that we need to supplement the list of positive and negative words in order to capture the extent of Megabus transportation-specific sentiments. We added a total of 57 sentiment related to Megabus and transportation experience. These additional negative and positive words were identified  by manually reviewing a random sample from 2900 tweets containing the keyword, "megabus" queried on 4/20/2016, following methods similar to those described here: http://www.wired.com/2015/02/best-worst-public-transit-systems-according-twitter/. This review comparing the Bing lexicon with Megabus tweets also revealed that a few sentiments already in the lexicon needed to be recorded or removed. These included: changing "uneventful" from negative to positive, reversing "cheap" from negative to positive given Megabus's platform as a cheap transportation provider, and the removal of "like" which could be positive or negative.

TO BE COMPLETED: describe cleaning and add any info on python

Load relevant packages and setup Twitter authorization.

```{r}
library(twitteR)
library(dplyr)
library(ggplot2)
library(ggthemes)

# setwd(dir = "/Users/eblisker/Documents/HSPH/Courses/2016 Spring/BIO 260/Final/megabummer")
# setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
```

Search twitter

```{r}
# tweets <- searchTwitter("megabus", n = 3500, lang="en")
# tweets_df <- bind_rows(lapply(tweets, as.data.frame))
```

### Exploratory Analysis

TO BE COMPLETED: What visualizations did you use to look at your data in different ways? What are the different statistical methods you considered? Justify the decisions you made, and show any major changes to your ideas. How did you reach these conclusions?

```{r}

```

### Final Analysis 

TO BE COMPLETED: What did you learn about the data? How did you answer the questions? How can you justify your answers?
