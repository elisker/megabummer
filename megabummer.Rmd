---
title: "Megabummer"
output: html_document
---

### Data Science BIO 260 Final Project, Spring 2016
##### Allison Blajda, Leo Brown, and Emily Lisker

### Overview and Motivation

Social media users leave digital traces that can be leveraged to guide consumer purchasing decisions. Twitter users, in particular, provide spatial and temporal data that can be analyzed to develop a more precise understanding of usersâ€™ perspectives or sentiments about a service, company, or product. This information, in turn, can be shared with the public to allow customers to make decisions based on crowd-sourced knowledge. It may also even help the service provider understand how they can improve their services.

Based on our own personal experiences, we aim to analyze recent tweets to understand the degree of negative experience among users of the low-cost bus company, Megabus, over time. While Megabus is an inexpensive and convenient transportation option with many buses departing major cities each day, we hypothesize that some Megabus routes and departure times may be more reliable, i.e., busses have fewer breakdowns and delays, than others. Using social media to understanding the predictors of negative Megabus experience, we may be able to offer future bus riders information that will help them avoid these experiences. 

Our primary goal is to understand the determinants of negative experience on Megabus, with a focus on temporality, in order to provide Megabus riders with information on the likelihood of service interruptions based on date and time.

### Related Work: 

TO BE COMPLETED: Anything that inspired you, such as a paper, a web site, or something we discussed in class.

### Initial Questions: 

TO BE COMPLETED: What questions are you trying to answer? How did these questions evolve over the course of the project? What new questions did you consider in the course of your analysis?

### Data: 

#### Data Scraping and Tidying
We scraped tweets with the keyword "megabus" during the period of January 1, 2015 through December 31, 2015 from the Twitter API using python package... 
[LEO TO UPDATE with what he actually did - did you have to use tidytext?] 

We imported four csv files, one for each quarter of tweets, as dataframes and thencombined the four quarters into one dataframe for the entire year. In order to look at variations in sentiment over days and time, we parsed the combined date and time variable into two new variables, containing just date and time information. 

We cleaned the data using dplyr and the tidytext package, in order to help with the text mining tasks necessary for sentiment analysis, available here: https://github.com/juliasilge/tidytext. 

#### Sentiment Analysis
Like most sentiment analyses, we relied on a lexicon of positive and negative words. We started with the Bing lexicon in the tidytext package in the sentiment dataset (described here in more detail https://www.cs.uic.edu/~liub/). This lexicon has been compiled over the past 12 years by researchers at the University of Illinois at Chicago. 

After initial review of the Bing lexicon, we realized that we need to supplement the list of positive and negative words in order to capture the extent of Megabus transportation-specific sentiments. We added a total of 57 sentiment related to Megabus and transportation experience. These additional negative and positive words were identified  by manually reviewing a random sample from 2900 tweets containing the keyword, "megabus" queried on 4/20/2016, following methods similar to those described here: http://www.wired.com/2015/02/best-worst-public-transit-systems-according-twitter/. This review comparing the Bing lexicon with Megabus tweets also revealed that a few sentiments already in the lexicon needed to be recorded or removed. These included: changing "uneventful" from negative to positive, reversing "cheap" from negative to positive given Megabus's platform as a cheap transportation provider, and the removal of "like" which could be positive or negative.

TO BE COMPLETED: describe cleaning and add any info on python

Load relevant packages and setup Twitter authorization.

```{r}
library(twitteR)
library(dplyr)
library(ggplot2)
library(ggthemes)

# setwd(dir = "/Users/eblisker/Documents/HSPH/Courses/2016 Spring/BIO 260/Final/megabummer")
# setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
```

Search twitter

```{r}
# tweets <- searchTwitter("megabus", n = 3500, lang="en")
# tweets_df <- bind_rows(lapply(tweets, as.data.frame))
```

### Exploratory Analysis

TO BE COMPLETED: What visualizations did you use to look at your data in different ways? What are the different statistical methods you considered? Justify the decisions you made, and show any major changes to your ideas. How did you reach these conclusions?

```{r}

```

### Final Analysis 

TO BE COMPLETED: What did you learn about the data? How did you answer the questions? How can you justify your answers?
